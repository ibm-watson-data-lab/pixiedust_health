{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install --user --exists-action=w -e git+'https://github.com/ibm-cds-labs/pixiedust@david-streaming-branch#egg=pixiedust'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "# import os\n",
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add your paths to the synthetic_data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_synthetic_data = './synthetic_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pixiedust": {
     "displayParams": {
      "handlerId": "dataframe"
     }
    }
   },
   "outputs": [],
   "source": [
    "demographics = pandas.read_csv(path_to_synthetic_data + 'create_v_demographic.csv', delimiter=\"\\t\")\n",
    "diagnosis = pandas.read_csv(path_to_synthetic_data + 'create_v_diagnosis.csv', delimiter=\"\\t\")\n",
    "observations = pandas.read_csv(path_to_synthetic_data + 'create_v_observation.csv', delimiter=\"\\t\")\n",
    "# histories = pandas.read_csv(path_to_synthetic_data + 'create_v_medical_history.csv', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display(demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pixiedust": {
     "displayParams": {
      "handlerId": "dataframe"
     }
    }
   },
   "outputs": [],
   "source": [
    "# display(diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pixiedust": {
     "displayParams": {
      "handlerId": "dataframe"
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pixiedust": {
     "displayParams": {
      "handlerId": "dataframe"
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Cohorts class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from six import iteritems\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from pixiedust.display import *\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Hopefully find a better way to do this if we expand to other diseases\n",
    "diseaseMap = {1: {'DisplayName': 'Diabetes', 'SnomedIDs': ['44054006', '359642000','81531005','237599002','199230006','609567009','237627000',\n",
    "                        '9859006','190331003','703138006','314903002','314904008','190390000','314772004',\n",
    "                        '314902007','190389009','313436004','1481000119100'], 'LoincIDs': ['4548-4', '29463-7','8302-2'], 'Features': ['HBA1C','WEIGHT','HEIGHT']}, \n",
    "              2: {'DisplayName': 'Hypertension', 'SnomedIDs': ['38341003'], 'LoincIDs': [], 'Features': ['BLOOD_PRESSURE']}}\n",
    "\n",
    "\n",
    "# Class for storing data and generating DataFrames and matrices for UI and machine learning\n",
    "# Requires 3 pandas data frames from create_v_demographic.csv, create_v_diagnosis.csv, and create_v_observation.csv\n",
    "# Columns expected in demogaphics: 'EXPLORYS_PATIENT_ID', 'STD_GENDER', 'BIRTH_YEAR', 'STD_RACE'\n",
    "# Columns expected in diagnosis: 'EXPLORYS_PATIENT_ID', 'DIAGNOSIS_DATE', 'SNOMED_IDS'\n",
    "# Columns expected in observations: 'EXPLORYS_PATIENT_ID', 'LOINC_TEST_ID', 'STD_VALUE'\n",
    "class Cohorts:\n",
    "    \n",
    "    #--------------------------------------- PRIVATE METHODS ---------------------------------------#\n",
    "    \n",
    "    ##-------------------------------------- Initialization --------------------------------------##\n",
    "    \n",
    "    def __init__(self, demographics, diagnosis, observations):\n",
    "        print \"demographics starting\"\n",
    "        self.demographics = self.__filterDemographics(demographics)\n",
    "        print \"demographics done\"\n",
    "        \n",
    "        print \"diagnosis starting\"\n",
    "        self.diagnosis = self.__filterDiagnosis(diagnosis)\n",
    "#         self.histories, self.diagnosis = self.__filterDiagnosis(diagnosis)\n",
    "        print \"diagnosis done\"\n",
    "        \n",
    "        print \"observations starting\"\n",
    "        self.observations = self.__getObservations(observations)\n",
    "        print \"observations done\"\n",
    "\n",
    "        self.demographicsFeatures = self.__getDemographicFeatures(observations)\n",
    "        \n",
    "        \n",
    "    # Returns filtered demographics data frame\n",
    "    # Requires original demographics chart\n",
    "    # Used in initial processing of data\n",
    "    def __filterDemographics(self, demographics):\n",
    "        filteredDemographics = demographics[['EXPLORYS_PATIENT_ID', 'STD_GENDER', 'BIRTH_YEAR', 'STD_ETHNICITY', 'STD_RACE', 'POSTAL_CODE_3']]\n",
    "        filteredDemographics[\"BIRTH_YEAR\"] = filteredDemographics.apply(lambda row: 2017 - row[\"BIRTH_YEAR\"],axis=1)\n",
    "        filteredDemographics.rename(columns={'BIRTH_YEAR':'AGE'}, inplace=True)\n",
    "        \n",
    "        # ethnicity to indices\n",
    "        dict_ethnicity = {'hispanic':1, 'non-hispanic':2, 'other':3, 'declined':4, 'unknown':4}\n",
    "        filteredDemographics[\"STD_ETHNICITY\"].replace(dict_ethnicity, inplace=True)\n",
    "        \n",
    "        # race to indices\n",
    "        dict_race = {101:1, 615:2, 203:3, 699:4}\n",
    "        filteredDemographics[\"STD_RACE\"].replace(dict_race, inplace=True)\n",
    "        \n",
    "        return filteredDemographics\n",
    "    \n",
    "    \n",
    "    # Returns diagnosis history data frame\n",
    "    # Requires original diagnosis histories chart\n",
    "    # Used in initial processing of data\n",
    "    def __filterDiagnosis(self, diagnosis):\n",
    "        filteredDiagnosis = diagnosis[['EXPLORYS_PATIENT_ID', 'DIAGNOSIS_DATE', 'SNOMED_IDS']]\n",
    "        snomedIDs = filteredDiagnosis['SNOMED_IDS'].map(lambda x: tuple(x.split(',')) if isinstance(x, str) else tuple())\n",
    "        filteredDiagnosis['SNOMED_IDS'] = snomedIDs.values\n",
    "        filteredDiagnosis = filteredDiagnosis.groupby(['EXPLORYS_PATIENT_ID', 'DIAGNOSIS_DATE'], as_index=False).sum()\n",
    "        return filteredDiagnosis\n",
    "    \n",
    "    \n",
    "    # Returns the BMI of a patient given their information in demographics\n",
    "    # Designed to be used in the apply function in getFeatures()\n",
    "    def __bmi(self, row):\n",
    "        return (row['WEIGHT'] / row['HEIGHT']**2) * 10000\n",
    "    \n",
    "    \n",
    "    def __getObservations(self, observations):\n",
    "        filteredObservations = observations[['EXPLORYS_PATIENT_ID', 'LOINC_TEST_ID', 'STD_VALUE', 'OBSERVATION_DATE']]\n",
    "        return filteredObservations\n",
    "    \n",
    "    \n",
    "    # Returns filtered observation data frame\n",
    "    # Requires original observations chart\n",
    "    # Used in initial processing of data\n",
    "    def __getDemographicFeatures(self, observations):\n",
    "        demographicCopy = self.demographics\n",
    "        filteredObservations = observations[['EXPLORYS_PATIENT_ID', 'LOINC_TEST_ID', 'STD_VALUE']]\n",
    "        filteredObservations = filteredObservations.groupby(['EXPLORYS_PATIENT_ID', 'LOINC_TEST_ID'], as_index=False).mean()\n",
    "        loincIDs = [('HBA1C', '4548-4'), ('WEIGHT', '29463-7'), ('HEIGHT', '8302-2')]\n",
    "        for label, loinc in loincIDs:\n",
    "            justThisLabel = filteredObservations.loc[filteredObservations['LOINC_TEST_ID'] == loinc]\n",
    "            justThisLabel = justThisLabel.rename(columns={'STD_VALUE': label})\n",
    "            demographicCopy = demographicCopy.merge(justThisLabel.drop('LOINC_TEST_ID', 1))\n",
    "        bmis = demographicCopy[['WEIGHT', 'HEIGHT']].apply(self.__bmi, axis=1)\n",
    "        demographicCopy['BMI'] = bmis.values\n",
    "        return demographicCopy\n",
    "    \n",
    "    \n",
    "    ##------------------------ Utility functions for filtering by disease ------------------------##\n",
    "    \n",
    "    # Returns a list of all patients we have a medical history for\n",
    "    # Facilitates getPatientsWithoutDisease()\n",
    "    def __getPatients(self):\n",
    "        return set(self.diagnosis['EXPLORYS_PATIENT_ID'].values)\n",
    "    \n",
    "    \n",
    "    # Returns list of IDs for patients with a given disease\n",
    "    # Requires disease ID\n",
    "    # Facilitates getDemographics() and used in machine learning component\n",
    "    def __getPatientsWithDisease(self, diseaseID):\n",
    "        snomedIDs = diseaseMap[diseaseID]['SnomedIDs']\n",
    "        filtered = self.diagnosis.loc[[not (set(item).isdisjoint(snomedIDs)) for item in self.diagnosis['SNOMED_IDS']]]\n",
    "        return set(filtered['EXPLORYS_PATIENT_ID'].values)\n",
    "    \n",
    "    \n",
    "    # Returns list of IDs for patients without a given disease\n",
    "    # Requires disease ID\n",
    "    # Facilitates getDemographics() and used in machine learning component\n",
    "    def __getPatientsWithoutDisease(self, diseaseID):\n",
    "        return self.__getPatients() - self.__getPatientsWithDisease(diseaseID)\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------#\n",
    "        \n",
    "    # Returns the first date (if multiple) that a patient has recorded corresponding to SNOMED for diseaseID\n",
    "    def __getDiagnosisDate(self, patientID, diseaseID):\n",
    "        patient_diagnosis = self.diagnosis.loc[self.diagnosis['EXPLORYS_PATIENT_ID'] == patientID]\n",
    "        snomedIDs = diseaseMap[diseaseID]['SnomedIDs']\n",
    "        filtered = patient_diagnosis.loc[[not (set(item).isdisjoint(snomedIDs)) for item in patient_diagnosis['SNOMED_IDS']]]\n",
    "        return min(list(set(filtered['DIAGNOSIS_DATE'].values)))\n",
    "    \n",
    "    \n",
    "    # Returns the observation table filtered on single loincID -- used in calculating average features\n",
    "    def __getFilteredLoinc(self, loincID):\n",
    "        filtered_obs = self.observations.loc[self.observations['LOINC_TEST_ID'] == loincID]\n",
    "        # convert observation dates to datetime\n",
    "        filtered_obs['OBSERVATION_DATE'] = filtered_obs.apply(lambda row: (datetime.strptime(row['OBSERVATION_DATE'], '%Y-%m-%d %H:%M:%S')),axis=1)\n",
    "        return filtered_obs\n",
    "    \n",
    "    \n",
    "    # Returns dataframe for patients with diseaseID from diagnosis table, and date/prev year date in datetime object form\n",
    "    def __filterDiagnosisDateForDisease(self, diseaseID):\n",
    "        snomedIDs = diseaseMap[diseaseID]['SnomedIDs']\n",
    "        filtered = self.diagnosis.loc[[not (set(item).isdisjoint(snomedIDs)) for item in self.diagnosis['SNOMED_IDS']]]\n",
    "        filtered.drop('SNOMED_IDS',axis=1, inplace=True)\n",
    "        filtered['DIAGNOSIS_DATE'] = filtered.apply(lambda row: datetime.strptime(row['DIAGNOSIS_DATE'], '%Y-%m-%d %H:%M:%S'),axis=1)\n",
    "        min_diagnosis_date = filtered.loc[filtered.groupby(\"EXPLORYS_PATIENT_ID\")[\"DIAGNOSIS_DATE\"].idxmin()]\n",
    "        min_diagnosis_date['ONE_YEAR_PREV'] = min_diagnosis_date.apply(lambda row: (row['DIAGNOSIS_DATE'] - relativedelta(years=1)),axis=1)\n",
    "        return min_diagnosis_date\n",
    "    \n",
    "    \n",
    "    # Returns dataframe with LOINC ID feature values averaged for the observations in the 12 months prior to diagnosis\n",
    "    def __getAvgFeatures(self,diseaseID, loincID, label):\n",
    "        # returns df for patients with loincID from observation table\n",
    "        patient_obs = self.__getFilteredLoinc(loincID)\n",
    "        # returns df for patients with diseaseID from diagnosis table\n",
    "        pos_diagnosis_dates = self.__filterDiagnosisDateForDisease(diseaseID)\n",
    "        # join the filtered obs and diagnosis table to get patients with data in both\n",
    "        obs_diag_merge = patient_obs.merge(pos_diagnosis_dates, how='inner', on='EXPLORYS_PATIENT_ID')\n",
    "        # gets people with diagnosis date and with the features needed for the disease\n",
    "        # filter out observations for patients not in year prior to diagnosis date\n",
    "        obs_diag_merge[obs_diag_merge.apply(lambda row: row['ONE_YEAR_PREV']<=row['OBSERVATION_DATE']<=row['DIAGNOSIS_DATE'],axis=1)]\n",
    "        obs_diag_merge.drop(['LOINC_TEST_ID', 'DIAGNOSIS_DATE', 'ONE_YEAR_PREV'],axis=1, inplace=True)\n",
    "        # calculate average value for patients with records on the same day\n",
    "        obs_avg_day = (obs_diag_merge.groupby(['EXPLORYS_PATIENT_ID', 'OBSERVATION_DATE'])).mean().reset_index()\n",
    "        obs_avg_day.drop(['OBSERVATION_DATE'],axis=1, inplace=True)\n",
    "        # calculate average value for each patient (12mos prior to diagnosis)\n",
    "        obs_avg_patient = obs_avg_day.groupby(['EXPLORYS_PATIENT_ID']).mean().reset_index()\n",
    "        obs_avg_patient.rename(columns={'STD_VALUE':label}, inplace=True)\n",
    "        return obs_avg_patient\n",
    "    \n",
    "    \n",
    "    # Returns dataframe with demographics joined with LOINC ID features for patients positive for a disease\n",
    "    def __getPosSetFeatures(self, diseaseID, features=None):\n",
    "        loincIDs = [('HBA1C', '4548-4'), ('WEIGHT', '29463-7'), ('HEIGHT', '8302-2')]\n",
    "        # get demographics table for people with disease\n",
    "        features = self.getDemographics(diseaseID)['pos'].drop(['HBA1C', 'WEIGHT', 'HEIGHT', 'BMI'], axis=1)\n",
    "        for label, loincID in loincIDs:\n",
    "            avg_loinc = self.__getAvgFeatures(diseaseID, loincID, label)\n",
    "            # merge tables for loinc features and demographics -> feature vectors for positive set\n",
    "            features = avg_loinc.merge(features, how='inner', on='EXPLORYS_PATIENT_ID')\n",
    "        features['BMI'] = features.apply(self.__bmi,axis=1)\n",
    "        return features\n",
    "    \n",
    "    \n",
    "    # Returns dataframe with the most recent LOINC ID feature value for patients without the disease\n",
    "    def __getNegLoincFeature(self, diseaseID, loincID, label):\n",
    "        #loincID = diseaseMap[diseaseID]['LoincIDs'][featureIdx]\n",
    "        # returns df for patients with loincID from observation table\n",
    "        patient_obs = self.__getFilteredLoinc(loincID)\n",
    "        # filter patients who don't have any observations for the features corresponding to the disease\n",
    "        negIDs = self.__getPatientsWithoutDisease(diseaseID)\n",
    "        neg_obs = patient_obs[patient_obs['EXPLORYS_PATIENT_ID'].isin(negIDs)]\n",
    "        # get most recent date for observation of loinc feature\n",
    "        recent_obs_date = neg_obs.loc[neg_obs.groupby(\"EXPLORYS_PATIENT_ID\")[\"OBSERVATION_DATE\"].idxmax()]\n",
    "        recent_obs_date.drop(['LOINC_TEST_ID', 'OBSERVATION_DATE'],axis=1, inplace=True)\n",
    "        recent_obs_date.rename(columns={'STD_VALUE':label}, inplace=True)\n",
    "        return recent_obs_date\n",
    "    \n",
    "    \n",
    "    # Returns dataframe with demographics joined with LOINC ID features for patients negative for a disease\n",
    "    def __getNegSetFeatures(self, diseaseID):\n",
    "        loincIDs = [('HBA1C', '4548-4'), ('WEIGHT', '29463-7'), ('HEIGHT', '8302-2')]\n",
    "        # get demographics table for people with disease\n",
    "        features = self.getDemographics(diseaseID)['neg'].drop(['HBA1C', 'WEIGHT', 'HEIGHT', 'BMI'], axis=1)\n",
    "        for label, loincID in loincIDs:\n",
    "            loinc_feature = self.__getNegLoincFeature(diseaseID, loincID, label)\n",
    "            # merge tables for loinc features and demographics -> feature vectors for positive set\n",
    "            features = loinc_feature.merge(features, how='inner', on='EXPLORYS_PATIENT_ID')\n",
    "        features['BMI'] = features.apply(self.__bmi,axis=1)\n",
    "        return features\n",
    "    \n",
    "    \n",
    "    #--------------------------------------- PUBLIC METHODS ---------------------------------------#\n",
    "    \n",
    "    # Returns list of (DisplayName, ID) for all diseases we have data for\n",
    "    # Designed for drop-down menu in initial window of UI\n",
    "    # Example return: [('Diabetes', 1), ('Hypertension', 2)]\n",
    "    def getDiseases(self):\n",
    "        return [(value['DisplayName'], key) for key, value in iteritems(diseaseMap)]\n",
    "    \n",
    "    \n",
    "    # Returns a dictionary of Data Frames, one for demographics and stats for patients with the given disease (key 'pos') \n",
    "    #   and one for patients who don't have that disease (key 'neg')\n",
    "    # Columns in returned data frames: 'EXPLORYS_PATIENT_ID', 'STD_GENDER', 'STD_ETHNICITY', 'STD_RACE', 'AGE', 'HBA1C', 'WEIGHT', 'HEIGHT', 'BMI'\n",
    "    # Had to calculate age  from birth year and BMI from weight and height\n",
    "    # Designed for descriptive analytics window of UI and to use in getFeatureVectors()\n",
    "    # This part is split into 2 separate data frames so the information shown in the pixieapp is just the people with the disease\n",
    "    def getDemographics(self, diseaseID):\n",
    "        pos_patients = self.__getPatientsWithDisease(diseaseID)\n",
    "        neg_patients = self.__getPatientsWithoutDisease(diseaseID)\n",
    "        pos_demographics = self.demographicsFeatures.loc[self.demographicsFeatures['EXPLORYS_PATIENT_ID'].isin(pos_patients)]\n",
    "        neg_demographics = self.demographicsFeatures.loc[self.demographicsFeatures['EXPLORYS_PATIENT_ID'].isin(neg_patients)]\n",
    "        return {'pos': pos_demographics, 'neg': neg_demographics}\n",
    "    \n",
    "    \n",
    "    # Returns a data frame including both patients with and without given disease\n",
    "    # HAS_DISEASE column indicates whether a patient has the disease (1) or not (0)\n",
    "    # Returns only certain features if features are specified\n",
    "    # Columns returned by default: 'STD_GENDER', 'AGE', 'STD_ETHNICITY', 'STD_RACE', 'HBA1C', 'WEIGHT', 'HEIGHT', 'BMI', 'HAS_DISEASE'\n",
    "    # Out of the positive and negative patients, the bigger group is cut down to be the same size as the smaller group\n",
    "    # Used in machine learning component\n",
    "    def getFeatureVectors(self, diseaseID):\n",
    "        pos_features = self.__getPosSetFeatures(diseaseID)\n",
    "        neg_features = self.__getNegSetFeatures(diseaseID)\n",
    "        size = min(len(pos_features.index), len(neg_features.index))\n",
    "        pos_features = pos_features.sample(n=size)\n",
    "        pos_features['HAS_DISEASE'] = 1\n",
    "        neg_features = neg_features.sample(n=size)\n",
    "        neg_features['HAS_DISEASE'] = 0\n",
    "        data = pd.concat([pos_features, neg_features])\n",
    "        data.drop(['POSTAL_CODE_3'], axis=1, inplace=True)\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    # Returns a data frame including both patients with and without given disease to be fed into the model \n",
    "    # Purpose of this function is to accomodate the ability to select features in the app without the need to recompute all columns\n",
    "    # Feature Columns returned by default: 'STD_GENDER', 'AGE', 'STD_ETHNICITY', 'STD_RACE', 'HBA1C', 'WEIGHT', 'HEIGHT', 'BMI'\n",
    "    # features argument must be some subset of the default columns in an array (that you wish to include)\n",
    "    def getFeaturesForModel(self, data, features=None):\n",
    "        if features != None:\n",
    "            features.insert(0, 'EXPLORYS_PATIENT_ID')\n",
    "            features.append('HAS_DISEASE')\n",
    "            return data[features]\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    #-------------------------------------- Building the Model -------------------------------------#\n",
    "        \n",
    "    # Returns training and testing data and label sets split 80/20\n",
    "    # in the order: training data, training labels, testing data, testing labels\n",
    "    # data is the table returned from getFeaturesForModel()\n",
    "    def getTrainTestSets(self, data):\n",
    "        ## CREATE TRAINING SET\n",
    "        data['is_train'] = np.random.uniform(0, 1, len(data)) <= .80\n",
    "        ## SPLIT INTO TRAINING AND TESTING SETS\n",
    "        x_train, x_test = data[data['is_train']==True], data[data['is_train']==False]\n",
    "        y_train = x_train['HAS_DISEASE']\n",
    "        y_test = x_test['HAS_DISEASE']\n",
    "        return x_train, y_train, x_test, y_test\n",
    "    \n",
    "    \n",
    "    # Returns array of the features to be used in the model from the data set\n",
    "    # data is the table returned from getFeaturesForModel()\n",
    "    def getFeatureNames(self, data):\n",
    "        # Create a list of the feature column's names\n",
    "        features = [item.encode('utf8') for item in data.columns]\n",
    "        features = features[1:len(features)-2]\n",
    "        return features\n",
    "    \n",
    "    \n",
    "    # Returns trained \n",
    "    # takes in formatted data frame for people with and without the disease from cohorts class\n",
    "    # data is output of getFeaturesForModel()\n",
    "    def getRandomForestClassifier(self, x_train, y_train, x_test, features):\n",
    "        # Create a random forest classifier. By convention, clf means 'classifier'\n",
    "        clf = RandomForestClassifier(n_jobs=2)\n",
    "        # Train the classifier to take the training features and learn how they relate to the training y\n",
    "        clf.fit(x_train[features], y_train) #The classifier model itself is stored in the clf variable.\n",
    "\n",
    "        # View the predicted probabilities of the first 10 observations\n",
    "        #clf.predict_proba(x_test[features])[0:10]\n",
    "\n",
    "        # Apply the classifier we trained to the test data\n",
    "        y_preds = clf.predict(x_test[features])\n",
    "        return clf, y_preds\n",
    "    \n",
    "    \n",
    "    ## Returns feature importance as determined by the trained model\n",
    "    # clf is the variable the classifier is stored in\n",
    "    def featureImportance(self, clf, x_train, features):\n",
    "        # View a list of the features and their importance scores\n",
    "        return list(zip(x_train[features], clf.feature_importances_))\n",
    "    \n",
    "    \n",
    "    ## Returns the scores for accuracy, precision, and recall based on \n",
    "    def getClassifierMetrics(self, clf, y_test, y_preds):\n",
    "        accuracy = metrics.accuracy_score(y_test, y_preds)\n",
    "        precision = metrics.precision_score(y_test, y_preds)\n",
    "        recall = metrics.recall_score(y_test, y_preds)\n",
    "        return accuracy, precision, recall\n",
    "    \n",
    "    \n",
    "    # NEEDS HELP - need to know more about ROC curves\n",
    "    def getROC(self, ):\n",
    "        #roc = metrics.roc_curve(y_)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    ## CROSS VALIDATION LEARN\n",
    "    def getCrossVal(self, data, features):\n",
    "        x_set = data[features]\n",
    "        y_set = data['HAS_DISEASE']\n",
    "        return cross_val_score(clf, x_set, y_set, cv=10)\n",
    "    \n",
    "    \n",
    "    #------------------------------------------ Geo Map --------------------------------------------#\n",
    "        \n",
    "    def getzip3geo(self, zip3df, zip3dfzipcol):\n",
    "        queryurl = \"https://opendata.cloudant.com/zip3-us/_design/views/_view/zip\"\n",
    "        queryurl += \"?limit=200&reduce=false&include_docs=true&keys=\"\n",
    "        q = (','.join('\"' + str(item) + '\"' for item in zip3df[zip3dfzipcol].unique()))\n",
    "        q = '[' + q + ']'\n",
    "        queryurl += q\n",
    "        res = requests.get(queryurl)\n",
    "        resj = res.json()\n",
    "        docs = []\n",
    "        for row in resj['rows']: \n",
    "            docs.append({ zip3dfzipcol:row['doc']['properties']['ZIP'], \n",
    "                         'pop':row['doc']['properties']['POP'], \n",
    "                         'geometry':json.dumps(row['doc']['geometry'])})\n",
    "\n",
    "        geodf = pd.DataFrame(docs)\n",
    "        geodf = pd.merge(geodf, zip3df, on=zip3dfzipcol)\n",
    "        return geodf\n",
    "    \n",
    "    \n",
    "    # Returns the data frame used in displaying the chloropleth map for patients with a diease in the country\n",
    "    # uses the function getzip3geo\n",
    "    def geoFormatPostal(self, diseaseID):\n",
    "        pos_demographics = self.getDemographics(diseaseID)['pos']\n",
    "        #pos_demographics_merged = pos_demographics.merge(self.demographics, on='EXPLORYS_PATIENT_ID', how='inner')\n",
    "        pos_postal = pos_demographics[['POSTAL_CODE_3']]\n",
    "        pos_postal = pos_postal[np.isfinite(pos_postal['POSTAL_CODE_3'])]\n",
    "        pos_postal = pos_postal.astype(float).astype(int).astype(str)\n",
    "        pos_postal['POSTAL_CODE_3'] = pos_postal.apply(lambda row: row['POSTAL_CODE_3'].zfill(3), axis=1) \n",
    "        pos_postal['ABS_COUNTS'] = pos_postal.groupby(['POSTAL_CODE_3'])['POSTAL_CODE_3'].transform('count')\n",
    "        pos_postal = pos_postal.drop_duplicates(subset='POSTAL_CODE_3', keep=\"first\")\n",
    "\n",
    "        geodf = self.getzip3geo(pos_postal,'POSTAL_CODE_3')\n",
    "        geodf['PROPORTION'] = geodf.apply(lambda row: float(row['ABS_COUNTS'])/float(row['pop']), axis=1)\n",
    "        return geodf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "cohorts = Cohorts(demographics, diagnosis, observations)\n",
    "print(\"- %s seconds -\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "diabetes = 1\n",
    "data = cohorts.getFeatureVectors(diabetes)\n",
    "print(\"- %s seconds -\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pixiedust": {
     "displayParams": {
      "handlerId": "dataframe"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = cohorts.getTrainTestSets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = cohorts.getFeatureNames(data)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf, Y_preds = cohorts.getRandomForestClassifier(X_train, Y_train, X_test, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lst = cohorts.featureImportance(clf, X_train, features)\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy,precision,recall = cohorts.getClassifierMetrics(clf, Y_test, Y_preds)\n",
    "print(accuracy,precision,recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crossval = cohorts.getCrossVal(data, features)\n",
    "print(crossval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diseaseID = 1 #diabetes\n",
    "geodf = cohorts.geoFormatPostal(diseaseID)\n",
    "geodf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "handlerId": "mapView",
      "keyFields": "geometry",
      "mapboxtoken": "pk.eyJ1IjoibWFwYm94IiwiYSI6ImNpejY4M29iazA2Z2gycXA4N2pmbDZmangifQ.-g_vE53SD2WrJ6tFX7QHmA",
      "rendererId": "mapbox",
      "rowCount": "500",
      "valueFields": "PROPORTION"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(geodf, debug='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display(geodf,cell_id='C04EEF368BA749398A6FC1FC3A3BDDB1',nostore_pixiedust='true',rowCount='500',handlerId='mapView',valueFields='PROPORTION',rendererId='mapbox',keyFields='geometry',aggregation='SUM',mapboxtoken='pk.eyJ1IjoibWFwYm94IiwiYSI6ImNpejY4M29iazA2Z2gycXA4N2pmbDZmangifQ.-g_vE53SD2WrJ6tFX7QHmA',nostore_cw='1098',org_params='gen_tests,nostore_pixiedust',nostore_bokeh='false',prefix='e5b3caf4')\n",
    "%pixiedustLog -l debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create instance of Cohorts and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cohorts = Cohorts(demographics, diagnosis, observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 0: Dropdown menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from pixiedust_health.cohort import *\n",
    "# cohorts = Cohorts('/Users/elizabethwells/PycharmProjects/WatsonHealth/synthetic_data')\n",
    "cohorts.getDiseases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 1: Descriptive Analytics / Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "clusterby": "WEIGHT",
      "handlerId": "pieChart",
      "keyFields": "STD_RACE",
      "rendererId": "matplotlib",
      "rowCount": "500",
      "valueFields": "AGE"
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "demographicDF = cohorts.getDemographics(1)['pos']\n",
    "display(demographicDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display(demographicDF,cell_id='35CB5B3CCBB64FBC926A890CA2F015E2',nostore_pixiedust='true',clusterby='WEIGHT',rowCount='500',handlerId='pieChart',valueFields='AGE',rendererId='matplotlib',keyFields='STD_RACE',aggregation='SUM',nostore_cw='1098',org_params='gen_tests,nostore_pixiedust',nostore_bokeh='false',prefix='dd038e2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "handlerId": "scatterPlot",
      "keyFields": "BMI",
      "rowCount": "500",
      "valueFields": "HBA1C"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(demographicDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display(demographicDF,cell_id='A275538E87D444648C8FCBBDE2F90FAF',nostore_pixiedust='true',rowCount='500',handlerId='scatterPlot',valueFields='HBA1C',keyFields='BMI',aggregation='SUM',nostore_cw='1097',org_params='gen_tests,nostore_pixiedust',nostore_bokeh='false',prefix='91615a4a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "handlerId": "histogram",
      "keyFields": "STD_GENDER",
      "rowCount": "500",
      "valueFields": "AGE"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(demographicDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display(demographicDF,cell_id='611A8C946D0E476ABFD2BED2AC2C9F47',nostore_pixiedust='true',rowCount='500',handlerId='histogram',valueFields='AGE',keyFields='STD_GENDER',aggregation='SUM',nostore_cw='1097',org_params='gen_tests,nostore_pixiedust',nostore_bokeh='false',prefix='697e4185')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "handlerId": "pieChart",
      "keyFields": "STD_GENDER",
      "rowCount": "500",
      "valueFields": "AGE"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(demographicDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display(demographicDF,cell_id='834A26A2628B4640BE4AF0A9E4F52577',nostore_pixiedust='true',rowCount='500',handlerId='pieChart',valueFields='AGE',keyFields='STD_GENDER',aggregation='SUM',nostore_cw='1097',org_params='gen_tests,nostore_pixiedust',nostore_bokeh='false',prefix='a00a17d8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure pixie app is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment to install pixiedust_health from a local repository\n",
    "# ATTN: replace with your path to the pixiedust_health repository\n",
    "# !pip install -e /Users/katiecarlson/pixiedust_health\n",
    "!pip install --upgrade --no-deps -e /Users/jbarbosa/blue/cds/git/pixiedust_health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pixiedust": {
     "displayParams": {
      "targetDivId": "dialog22c739d3root"
     }
    }
   },
   "outputs": [],
   "source": [
    "from pixiedust_health import *\n",
    "PixieHealthApp().run(cohorts, runInDialog='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 2: Classsification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "handlerId": "dataframe",
      "keyFields": "HAS_DISEASE",
      "rowCount": "500",
      "valueFields": "WEIGHT"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display(cohorts.getFeatureVectors(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "handlerId": "dataframe",
      "keyFields": "HAS_DISEASE",
      "rowCount": "500",
      "valueFields": "BMI"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display(cohorts.getFeatureVectors(2, ['AGE', 'BMI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python with Pixiedust (Spark 2.1)",
   "language": "python",
   "name": "pythonwithpixiedustspark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
